{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce849f3f-32cf-4728-bd1f-5ae355cf17cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "\n",
    "import torch\n",
    "\n",
    "tqdm.pandas()\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faaccc47-fcda-4757-8658-0d2fdfcdb15f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filename_clean</th>\n",
       "      <th>source_text</th>\n",
       "      <th>Main.Point</th>\n",
       "      <th>Details</th>\n",
       "      <th>Cohesion</th>\n",
       "      <th>Objective.Language</th>\n",
       "      <th>Wording.Para</th>\n",
       "      <th>Lang..Bey..ST</th>\n",
       "      <th>Summ..Length</th>\n",
       "      <th>content_pca</th>\n",
       "      <th>paraphrase_pca</th>\n",
       "      <th>text</th>\n",
       "      <th>source_text_clean</th>\n",
       "      <th>source_text_filename_clean</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1091_CivilServices .txt</td>\n",
       "      <td>1091_CivilServices</td>\n",
       "      <td>CivilService.txt</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.785</td>\n",
       "      <td>hard work pays off  /  / \\n</td>\n",
       "      <td>CivilService</td>\n",
       "      <td>11_CivilService</td>\n",
       "      <td>\\nCivil service offers jobs to thousands of me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filename      filename_clean       source_text  Main.Point  \\\n",
       "1  1091_CivilServices .txt  1091_CivilServices  CivilService.txt         0.5   \n",
       "\n",
       "   Details  Cohesion  Objective.Language  Wording.Para  Lang..Bey..ST  \\\n",
       "1      0.5       0.5                 0.5           0.5            0.5   \n",
       "\n",
       "   Summ..Length  content_pca  paraphrase_pca                         text  \\\n",
       "1           0.5         1.37           0.785  hard work pays off  /  / \\n   \n",
       "\n",
       "  source_text_clean source_text_filename_clean  \\\n",
       "1      CivilService            11_CivilService   \n",
       "\n",
       "                                              source  \n",
       "1  \\nCivil service offers jobs to thousands of me...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    pd.read_csv(\n",
    "        '/home/jovyan/active-projects/summary-scoring/data/final_summaries_ai_aloe_fixed.csv',\n",
    "        index_col=2)\n",
    "    .iloc[:,2:] # remove garbage index columns from repeatedly saving to csv with pandas.\n",
    "    .rename_axis(None) # remove the index name \"Row.names\" -- This appears to be the original index.\n",
    ")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb2426c7-e74f-4e66-92fb-282e3232cb35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4690/4690 [00:39<00:00, 117.52it/s]\n"
     ]
    }
   ],
   "source": [
    "df['text_lemmatized'] = [' '.join([t.lemma_ for t in doc]) for doc in nlp.pipe(tqdm(df.text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd51a608-5021-4056-8c91-822843732c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_dicts = {}\n",
    "\n",
    "for row in df.itertuples():\n",
    "    if row.source_text_filename_clean in source_dicts.keys():\n",
    "        # ensure that that \"row.source_text_clean\" uniquely identifies the source text\n",
    "        assert source_dicts[row.source_text_filename_clean]['text'] == row.source\n",
    "    else:\n",
    "        source_dicts[row.source_text_filename_clean] = {\n",
    "            'text': row.source,\n",
    "            'text_lemmatized': ' '.join([t.lemma_ for t in nlp(row.source)])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d63346fd-5b1d-45e2-8751-484d755c8c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    Text2TextGenerationPipeline,\n",
    ")\n",
    "\n",
    "class KeyphraseGenerationPipeline(Text2TextGenerationPipeline):\n",
    "    def __init__(self, model, keyphrase_sep_token=';', *args, **kwargs):\n",
    "        super().__init__(\n",
    "            model=AutoModelForSeq2SeqLM.from_pretrained(model),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model,\n",
    "                                                    truncation=True,\n",
    "                                                    max_length=256,\n",
    "                                                    ),\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.keyphrase_sep_token = keyphrase_sep_token\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        results = super().postprocess(model_outputs=model_outputs)\n",
    "        return [\n",
    "            [\n",
    "                keyphrase.strip().translate(str.maketrans('', '', string.punctuation))\n",
    "                for keyphrase in result.get('generated_text').split(\n",
    "                    self.keyphrase_sep_token\n",
    "                )\n",
    "                if keyphrase.translate(str.maketrans('', '', string.punctuation)) != ''\n",
    "            ]\n",
    "            for result in results\n",
    "        ][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5ce3ee9-5a6d-4d87-b97d-8914e38eb4a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum token count: 684\n"
     ]
    }
   ],
   "source": [
    "print('Maximum token count:', max([len(source_dict['text'].split()) for source_dict in source_dicts.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11c5f4c2-aa45-4700-9d5b-3f910a1a2757",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 10/101 [00:03<00:31,  2.92it/s]/home/jovyan/conda_envs/keyword-extraction/lib/python3.11/site-packages/transformers/pipelines/base.py:1045: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 101/101 [00:34<00:00,  2.93it/s]\n"
     ]
    }
   ],
   "source": [
    "pipe = KeyphraseGenerationPipeline(model='bloomberg/KeyBART', device=0)\n",
    "\n",
    "for source, source_dict in tqdm(source_dicts.items()):\n",
    "    source_dict['keyterms_KeyBART'] = pipe(source_dict['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3953f36-4428-45b3-bd16-694127b8b288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def keyphrase_lower(row):\n",
    "    keyphrases = source_dicts[row.source_text_filename_clean]['keyterms_KeyBART']\n",
    "    summary = row.text\n",
    "    keyphrase_count = sum(\n",
    "        [(keyphrase.lower() in summary.lower())\n",
    "         for keyphrase in keyphrases]\n",
    "    )\n",
    "    return keyphrase_count\n",
    "\n",
    "df['keyterms_KeyBART_lower'] = df.apply(lambda row: keyphrase_lower(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e71d551e-66c6-4e0c-9770-3b25e3b5cd2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4690/4690 [00:41<00:00, 112.68it/s]\n"
     ]
    }
   ],
   "source": [
    "def keyphrase_lemma(row, split_phrases=False):\n",
    "    keyphrases = source_dicts[row.source_text_filename_clean]['keyterms_KeyBART']\n",
    "    \n",
    "    if split_phrases:\n",
    "        keyphrases = [t.lemma_ for doc in nlp.pipe(keyphrases) for t in doc]\n",
    "    else:\n",
    "        keyphrases = [' '.join([t.lemma_ for t in doc])\n",
    "                      for doc in nlp.pipe(keyphrases)] \n",
    "        \n",
    "    summary = row.text_lemmatized\n",
    "    \n",
    "    keyphrase_count = sum(\n",
    "        [(keyphrase.lower() in summary.lower())\n",
    "         for keyphrase in keyphrases]\n",
    "    )\n",
    "    \n",
    "    return keyphrase_count\n",
    "\n",
    "df['keyterms_KeyBART_lemma'] = df.progress_apply(lambda row: keyphrase_lemma(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8cdf5c33-79a9-481f-8e70-1f492a561eae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4690/4690 [00:41<00:00, 111.69it/s]\n"
     ]
    }
   ],
   "source": [
    "df['keyterms_KeyBART_lemma_split'] = df.progress_apply(lambda row: keyphrase_lemma(row, split_phrases=True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c42757e8-6246-48d2-8c38-444ab462a994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4690/4690 [00:01<00:00, 2753.76it/s]\n"
     ]
    }
   ],
   "source": [
    "def overlapping_words(row):\n",
    "    source_lemmas = source_dicts[row.source_text_filename_clean]['text_lemmatized'].split()\n",
    "\n",
    "    summary = row.text_lemmatized.split()\n",
    "    \n",
    "    lemma_count = sum(\n",
    "        [(lemma in summary)\n",
    "         for lemma in source_lemmas]\n",
    "    )\n",
    "\n",
    "    return lemma_count\n",
    "\n",
    "df['lemmas'] = df.progress_apply(lambda row: overlapping_words(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f36f0f93-9ff4-4677-a223-b19e0b17a6a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_pca</th>\n",
       "      <th>paraphrase_pca</th>\n",
       "      <th>keyterms_KeyBART_lower</th>\n",
       "      <th>keyterms_KeyBART_lemma</th>\n",
       "      <th>keyterms_KeyBART_lemma_split</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>content_pca</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660600</td>\n",
       "      <td>0.211796</td>\n",
       "      <td>0.223199</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.279160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paraphrase_pca</th>\n",
       "      <td>0.660600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005417</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.109170</td>\n",
       "      <td>-0.018682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyterms_KeyBART_lower</th>\n",
       "      <td>0.211796</td>\n",
       "      <td>-0.005417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978244</td>\n",
       "      <td>0.514628</td>\n",
       "      <td>0.339762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyterms_KeyBART_lemma</th>\n",
       "      <td>0.223199</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.978244</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522354</td>\n",
       "      <td>0.324745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyterms_KeyBART_lemma_split</th>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.109170</td>\n",
       "      <td>0.514628</td>\n",
       "      <td>0.522354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.298050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemmas</th>\n",
       "      <td>0.279160</td>\n",
       "      <td>-0.018682</td>\n",
       "      <td>0.339762</td>\n",
       "      <td>0.324745</td>\n",
       "      <td>0.298050</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              content_pca  paraphrase_pca  \\\n",
       "content_pca                      1.000000        0.660600   \n",
       "paraphrase_pca                   0.660600        1.000000   \n",
       "keyterms_KeyBART_lower           0.211796       -0.005417   \n",
       "keyterms_KeyBART_lemma           0.223199        0.000403   \n",
       "keyterms_KeyBART_lemma_split     0.277350        0.109170   \n",
       "lemmas                           0.279160       -0.018682   \n",
       "\n",
       "                              keyterms_KeyBART_lower  keyterms_KeyBART_lemma  \\\n",
       "content_pca                                 0.211796                0.223199   \n",
       "paraphrase_pca                             -0.005417                0.000403   \n",
       "keyterms_KeyBART_lower                      1.000000                0.978244   \n",
       "keyterms_KeyBART_lemma                      0.978244                1.000000   \n",
       "keyterms_KeyBART_lemma_split                0.514628                0.522354   \n",
       "lemmas                                      0.339762                0.324745   \n",
       "\n",
       "                              keyterms_KeyBART_lemma_split    lemmas  \n",
       "content_pca                                       0.277350  0.279160  \n",
       "paraphrase_pca                                    0.109170 -0.018682  \n",
       "keyterms_KeyBART_lower                            0.514628  0.339762  \n",
       "keyterms_KeyBART_lemma                            0.522354  0.324745  \n",
       "keyterms_KeyBART_lemma_split                      1.000000  0.298050  \n",
       "lemmas                                            0.298050  1.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['content_pca', 'paraphrase_pca', 'keyterms_KeyBART_lower', 'keyterms_KeyBART_lemma', 'keyterms_KeyBART_lemma_split', 'lemmas']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "406b9c90-4193-4cf1-9852-92fbed5a6e79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyterms_KeyBART</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1241.0</td>\n",
       "      <td>7.171370</td>\n",
       "      <td>2.446901</td>\n",
       "      <td>0.76</td>\n",
       "      <td>5.4800</td>\n",
       "      <td>7.50</td>\n",
       "      <td>9.2100</td>\n",
       "      <td>10.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1662.0</td>\n",
       "      <td>8.124747</td>\n",
       "      <td>1.908272</td>\n",
       "      <td>0.76</td>\n",
       "      <td>6.8500</td>\n",
       "      <td>8.22</td>\n",
       "      <td>9.5900</td>\n",
       "      <td>10.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1149.0</td>\n",
       "      <td>8.502115</td>\n",
       "      <td>1.670218</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>8.66</td>\n",
       "      <td>9.8600</td>\n",
       "      <td>10.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>470.0</td>\n",
       "      <td>8.360128</td>\n",
       "      <td>1.553779</td>\n",
       "      <td>2.74</td>\n",
       "      <td>7.1925</td>\n",
       "      <td>8.49</td>\n",
       "      <td>9.5900</td>\n",
       "      <td>10.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147.0</td>\n",
       "      <td>8.290204</td>\n",
       "      <td>1.597337</td>\n",
       "      <td>4.05</td>\n",
       "      <td>7.2300</td>\n",
       "      <td>8.60</td>\n",
       "      <td>9.5900</td>\n",
       "      <td>10.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.0</td>\n",
       "      <td>9.388889</td>\n",
       "      <td>1.451680</td>\n",
       "      <td>6.30</td>\n",
       "      <td>8.6700</td>\n",
       "      <td>9.62</td>\n",
       "      <td>10.4925</td>\n",
       "      <td>10.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.640000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.64</td>\n",
       "      <td>9.6400</td>\n",
       "      <td>9.64</td>\n",
       "      <td>9.6400</td>\n",
       "      <td>9.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.960000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.96</td>\n",
       "      <td>10.9600</td>\n",
       "      <td>10.96</td>\n",
       "      <td>10.9600</td>\n",
       "      <td>10.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count       mean       std    min      25%    50%      75%  \\\n",
       "keyterms_KeyBART                                                                \n",
       "0                 1241.0   7.171370  2.446901   0.76   5.4800   7.50   9.2100   \n",
       "1                 1662.0   8.124747  1.908272   0.76   6.8500   8.22   9.5900   \n",
       "2                 1149.0   8.502115  1.670218   0.76   7.4000   8.66   9.8600   \n",
       "3                  470.0   8.360128  1.553779   2.74   7.1925   8.49   9.5900   \n",
       "4                  147.0   8.290204  1.597337   4.05   7.2300   8.60   9.5900   \n",
       "5                   18.0   9.388889  1.451680   6.30   8.6700   9.62  10.4925   \n",
       "6                    2.0   9.640000  0.000000   9.64   9.6400   9.64   9.6400   \n",
       "7                    1.0  10.960000       NaN  10.96  10.9600  10.96  10.9600   \n",
       "\n",
       "                    max  \n",
       "keyterms_KeyBART         \n",
       "0                 10.96  \n",
       "1                 10.96  \n",
       "2                 10.96  \n",
       "3                 10.96  \n",
       "4                 10.58  \n",
       "5                 10.96  \n",
       "6                  9.64  \n",
       "7                 10.96  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('keyterms_KeyBART').content_pca.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdbd7565-f0d7-411a-9925-01224a443285",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            content_pca   R-squared:                       0.077\n",
      "Model:                            OLS   Adj. R-squared:                  0.077\n",
      "Method:                 Least Squares   F-statistic:                     390.7\n",
      "Date:                Sun, 26 Mar 2023   Prob (F-statistic):           1.38e-83\n",
      "Time:                        19:25:43   Log-Likelihood:                -9809.4\n",
      "No. Observations:                4690   AIC:                         1.962e+04\n",
      "Df Residuals:                    4688   BIC:                         1.964e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================================\n",
      "                                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------\n",
      "const                            6.9775      0.059    118.040      0.000       6.862       7.093\n",
      "keyterms_KeyBART_lemma_split     0.2243      0.011     19.765      0.000       0.202       0.247\n",
      "==============================================================================\n",
      "Omnibus:                      299.677   Durbin-Watson:                   1.121\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              364.111\n",
      "Skew:                          -0.633   Prob(JB):                     8.60e-80\n",
      "Kurtosis:                       3.512   Cond. No.                         11.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "mod = sm.OLS(df.content_pca, sm.add_constant(df.keyterms_KeyBART_lemma_split))\n",
    "\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a82f9728-ee67-4d99-ab79-002063582315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         paraphrase_pca   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.1376\n",
      "Date:                Sun, 26 Mar 2023   Prob (F-statistic):              0.711\n",
      "Time:                        17:47:36   Log-Likelihood:                -7684.8\n",
      "No. Observations:                4690   AIC:                         1.537e+04\n",
      "Df Residuals:                    4688   BIC:                         1.539e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const                3.5209      0.028    124.646      0.000       3.465       3.576\n",
      "keyterms_KeyBART    -0.0062      0.017     -0.371      0.711      -0.039       0.027\n",
      "==============================================================================\n",
      "Omnibus:                      130.541   Durbin-Watson:                   1.340\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              139.432\n",
      "Skew:                          -0.414   Prob(JB):                     5.28e-31\n",
      "Kurtosis:                       2.833   Cond. No.                         3.23\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod = sm.OLS(df.paraphrase_pca, sm.add_constant(df.keyterms_KeyBART))\n",
    "\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keyword-extraction]",
   "language": "python",
   "name": "conda-env-keyword-extraction-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
