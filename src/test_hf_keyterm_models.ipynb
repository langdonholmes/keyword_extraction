{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available? True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f'CUDA is available? {torch.cuda.is_available()}')\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "import string\n",
    "from pathlib import Path\n",
    "project_dir = Path('/home/jovyan/active-projects/keyword-extraction')\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Doc, DocBin\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "for extension in ['section_url', 'subsection']:\n",
    "    if not Doc.has_extension(extension):\n",
    "        Doc.set_extension(extension, default=None)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "db = DocBin().from_disk(project_dir / 'data' / 'openstax-subsections.spacy')\n",
    "\n",
    "docs = list(db.get_docs(nlp.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (3723264391.py, line 45)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[72], line 45\u001b[0;36m\u001b[0m\n\u001b[0;31m    ),\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    Text2TextGenerationPipeline,\n",
    "    TokenClassificationPipeline,\n",
    ")\n",
    "\n",
    "from transformers.pipelines import AggregationStrategy\n",
    "\n",
    "class KeyphraseGenerationPipeline(Text2TextGenerationPipeline):\n",
    "    def __init__(self, model, keyphrase_sep_token=';', *args, **kwargs):\n",
    "        super().__init__(\n",
    "            model=AutoModelForSeq2SeqLM.from_pretrained(model),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model,\n",
    "                                                    truncation=True,\n",
    "                                                    max_length=256,\n",
    "                                                    ),\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.keyphrase_sep_token = keyphrase_sep_token\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        results = super().postprocess(model_outputs=model_outputs)\n",
    "        return [\n",
    "            [\n",
    "                keyphrase.strip().translate(str.maketrans('', '', string.punctuation))\n",
    "                for keyphrase in result.get('generated_text').split(\n",
    "                    self.keyphrase_sep_token\n",
    "                )\n",
    "                if keyphrase.translate(str.maketrans('', '', string.punctuation)) != ''\n",
    "            ]\n",
    "            for result in results\n",
    "        ][0]\n",
    "\n",
    "\n",
    "class KeyphraseExtractionPipeline(TokenClassificationPipeline):\n",
    "    def __init__(self, model, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            model=AutoModelForTokenClassification.from_pretrained(model),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model,\n",
    "                                                    truncation=True,\n",
    "                                                    ),\n",
    "            *args,\n",
    "            **{'model_max_length': 510}\n",
    "        )\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        results = super().postprocess(\n",
    "            model_outputs=model_outputs,\n",
    "            aggregation_strategy=AggregationStrategy.SIMPLE\n",
    "            if self.model.config.model_type == 'roberta'\n",
    "            else AggregationStrategy.FIRST,\n",
    "        )\n",
    "        return np.unique([result.get('word').strip() for result in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "  'extraction': [\n",
    "    'ml6team/keyphrase-extraction-kbir-inspec',\n",
    "    'ml6team/keyphrase-extraction-distilbert-inspec',\n",
    "    # 'ml6team/keyphrase-extraction-kbir-openkp',\n",
    "    'ml6team/keyphrase-extraction-distilbert-openkp',\n",
    "    'ml6team/keyphrase-extraction-kbir-kptimes',\n",
    "    'ml6team/keyphrase-extraction-distilbert-kptimes',\n",
    "    'ml6team/keyphrase-extraction-kbir-semeval2017',\n",
    "    'ml6team/keyphrase-extraction-kbir-kpcrowd',\n",
    "    ],\n",
    "  'generation': [\n",
    "    'ml6team/keyphrase-generation-keybart-inspec',\n",
    "    'ml6team/keyphrase-generation-t5-small-inspec',\n",
    "    'ml6team/keyphrase-generation-t5-small-openkp',\n",
    "    'bloomberg/KeyBART',\n",
    "  ]\n",
    "}\n",
    "\n",
    "samples = random.sample(docs, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml6team/keyphrase-extraction-kbir-inspec - https://openstax.org/books/college-algebra-corequisite-support-2e/pages/7-7-solving-systems-with-inverses - Finding the Multiplicative Inverse of 3×3 Matrices\n",
      "['Multiplicative Inverse' 'Solution Augment' 'elementary row operations'\n",
      " 'identity matrix' 'inverse' 'inverse matrix' 'matrix multiplication'\n",
      " 'row operations']\n",
      "\n",
      "ml6team/keyphrase-extraction-kbir-inspec - https://openstax.org/books/college-algebra-corequisite-support-2e/pages/5-5-zeros-of-polynomial-functions - Solving Real-World Applications \n",
      "['Polynomial Equations' 'Rational Zero Theorem' 'bakery problem' 'cake'\n",
      " 'polynomial equations' 'sheet cake' 'sheet cakes' 'wedding celebrations']\n",
      "\n",
      "ml6team/keyphrase-extraction-kbir-inspec - https://openstax.org/books/chemistry-2e/pages/12-5-collision-theory - Learning Objectives\n",
      "['Arrhenius equation' 'Carbon monoxide' 'Collision theory'\n",
      " 'activation energy' 'automobiles' 'carbon monoxide'\n",
      " 'catalytic converters' 'chemical bonds' 'chemical kinetics'\n",
      " 'collision theory' 'firearms' 'gunpowder' 'muzzle flash' 'rate'\n",
      " 'reactant collisions' 'reaction' 'reaction rates' 'temperature'\n",
      " 'transition state' 'valence shells']\n",
      "\n",
      "ml6team/keyphrase-extraction-kbir-inspec - https://openstax.org/books/college-algebra-corequisite-support-2e/pages/6-4-graphs-of-logarithmic-functions - Graphing a Horizontal Shift of \n",
      "[]\n",
      "\n",
      "ml6team/keyphrase-extraction-kbir-inspec - https://openstax.org/books/biology-ap-courses/pages/35-4-aquatic-biomes - Estuaries: Where the Ocean Meets Fresh Water\n",
      "['Animals' 'Caribbean Sea' 'Florida International University' 'Mollusca'\n",
      " 'Wikimedia Commons' 'aerobic respiration' 'anaerobic respiration'\n",
      " 'behavioral adaptations' 'biomes' 'clams' 'crustaceans' 'fish'\n",
      " 'mangroves' 'mollusks' 'mussels' 'organisms' 'physiological'\n",
      " 'protected areas' 'sea spray']\n",
      "\n",
      "ml6team/keyphrase-extraction-kbir-inspec - https://openstax.org/books/introduction-business/pages/13-1-transforming-businesses-through-information - Data and Information Systems\n",
      "['Information Systems' 'Information systems' 'Marketing'\n",
      " 'business analysis' 'business decisions' 'business information systems'\n",
      " 'business strategy' 'cost' 'customer database' 'data marts'\n",
      " 'data warehouses' 'electronic filing system'\n",
      " 'enterprise resource planning' 'finance' 'financial statements'\n",
      " 'human resources' 'information systems' 'inventory'\n",
      " 'management information systems' 'order history' 'order information'\n",
      " 'payment method' 'sales data']\n",
      "\n",
      "ml6team/keyphrase-extraction-kbir-inspec - https://openstax.org/books/biology-ap-courses/pages/24-1-animal-form-and-function - Body Plans\n",
      "['Animal body plans' 'Bilateral symmetry' 'Radial symmetry'\n",
      " 'aquatic animals' 'asymm' 'bilateral symmetry' 'body symmetry' 'goat'\n",
      " 'radial symmetry' 'sea anemone' 'sponge']\n",
      "\n",
      "ml6team/keyphrase-extraction-kbir-inspec - https://openstax.org/books/university-physics-volume-2/pages/14-2-self-inductance-and-inductors - Rectangular Toroid\n",
      "['Rectangular Toroid' 'emf' 'magnetic field' 'rectangular toroid'\n",
      " 'solenoid']\n",
      "\n",
      "ml6team/keyphrase-extraction-kbir-inspec - https://openstax.org/books/astronomy-2e/pages/22-1-evolution-from-the-main-sequence-to-red-giants - Learning Objectives\n",
      "['chemical composition' 'interior structure' 'nuclear fusion'\n",
      " 'nuclear reactions' 'protostars']\n",
      "\n",
      "ml6team/keyphrase-extraction-kbir-inspec - https://openstax.org/books/introduction-philosophy/pages/10-1-the-challenge-of-bioethics - Human Trials in Historically Marginalized Communities\n",
      "['Black men' 'Black sharecroppers' 'Historically' 'Human Trials'\n",
      " 'Marginalized Communities' 'Nazi physicians' 'Tuske'\n",
      " 'Tuskegee experiment' 'Tuskegee syphilis' 'United States'\n",
      " 'Vulnerable populations' 'World War II' 'coercion' 'human subjects'\n",
      " 'informed consent' 'language barriers' 'marginalized communities'\n",
      " 'penicillin' 'recruit' 'untreated syphilis' 'vulnerable populations']\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-inspec - https://openstax.org/books/college-algebra-corequisite-support-2e/pages/7-7-solving-systems-with-inverses - Finding the Multiplicative Inverse of 3×3 Matrices\n",
      "['3×3 matrices' 'augmented matrix' 'elementary' 'identity matrix'\n",
      " 'inverse matrix' 'multiplicative inverse' 'row operations']\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-inspec - https://openstax.org/books/college-algebra-corequisite-support-2e/pages/5-5-zeros-of-polynomial-functions - Solving Real-World Applications \n",
      "['bakery problem' 'cake pan' 'polynomial equations' 'quinceanera'\n",
      " 'rational zero theorem' 'rectangular solid' 'sheet cake' 'sheet cakes'\n",
      " 'subtract 1053' 'wedding celebrations']\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-inspec - https://openstax.org/books/chemistry-2e/pages/12-5-collision-theory - Learning Objectives\n",
      "['activation energy' 'arrhenius equation' 'automobiles' 'bonds'\n",
      " 'calculations relating rate constants' 'carbon monoxide' 'catalyst'\n",
      " 'catalytic converters' 'chemical bonds' 'chemical kinetics'\n",
      " 'chemical species' 'collision' 'collision theory'\n",
      " 'collisions time reaction rate' 'combustion' 'electrons' 'gunpowder'\n",
      " 'hydrocarbon fuels' 'molecule collides' 'mutual penetration'\n",
      " 'muzzle flash' 'orientation' 'oxygen molecule' 'physical state'\n",
      " 'postulates' 'reactant collisions' 'reacting species' 'reaction rates'\n",
      " 'side reaction' 'transition state' 'valence shells']\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-inspec - https://openstax.org/books/college-algebra-corequisite-support-2e/pages/6-4-graphs-of-logarithmic-functions - Graphing a Horizontal Shift of \n",
      "[]\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-inspec - https://openstax.org/books/biology-ap-courses/pages/35-4-aquatic-biomes - Estuaries: Where the Ocean Meets Fresh Water\n",
      "['bermuda' 'caribbean sea' 'crustaceans' 'estuaries'\n",
      " 'estuarine plant species' 'fresh water estuaries' 'gills' 'halophytes'\n",
      " 'halophytic plants' 'high tides' 'international' 'organisms'\n",
      " 'physiological' 'plants' 'rapid variation' 'salty conditions' 'sea spray'\n",
      " 'university']\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-inspec - https://openstax.org/books/introduction-business/pages/13-1-transforming-businesses-through-information - Data and Information Systems\n",
      "['address' 'business analysis' 'business decisions' 'business strategy'\n",
      " 'customer database' 'data marts' 'data warehouses'\n",
      " 'database management system' 'databases' 'dbms' 'departmental'\n",
      " 'electronic filing system' 'information systems'\n",
      " 'information systems information systems'\n",
      " 'management information systems' 'marketing' 'order history'\n",
      " 'payment method' 'products' 'systems']\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-inspec - https://openstax.org/books/biology-ap-courses/pages/24-1-animal-form-and-function - Body Plans\n",
      "['aquatic animals' 'asymmetrical animal' 'bilateral symmetry'\n",
      " 'body symmetry' 'goat' 'organisms' 'radial symmetry' 'sea anemone'\n",
      " 'sponge']\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-inspec - https://openstax.org/books/university-physics-volume-2/pages/14-2-self-inductance-and-inductors - Rectangular Toroid\n",
      "['central axis' 'flux' 'infinitesimal' 'magnetic field' 'magnetic flux'\n",
      " 'physical properties' 'rectangular' 'rectangular toroid' 'self'\n",
      " 'solenoid']\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-inspec - https://openstax.org/books/astronomy-2e/pages/22-1-evolution-from-the-main-sequence-to-red-giants - Learning Objectives\n",
      "['chemical composition' 'fusion' 'helium' 'hydrogen' 'nuclear fusion'\n",
      " 'nuclear reactions' 'proton' 'protons']\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-inspec - https://openstax.org/books/introduction-philosophy/pages/10-1-the-challenge-of-bioethics - Human Trials in Historically Marginalized Communities\n",
      "['americans' 'autonomy' 'black sharecroppers' 'coercion' 'desperate'\n",
      " 'goals' 'historically marginalized communities' 'human subjects'\n",
      " 'human trials' 'informed consent' 'language barriers'\n",
      " 'marginalized communities' 'medical care' 'nazi physicians'\n",
      " 'participation requirements' 'penicillin'\n",
      " 'prospective trial participants' 'syphilis' 'tuskegee experiment'\n",
      " 'tuskegee syphilis' 'united states' 'vulnerable populations']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff52267f329458094c62fad74368a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/697 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ab3abf5c894ce1b580dd4e6edb0c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/266M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebb47ff134c49ae8bd48eb99f29abef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add84a7c5b5a4d93978580224afac3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ecce20e0f574b5bb5990ad34b65dce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289660423fb343ba8fd160cd2f6a23c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml6team/keyphrase-extraction-distilbert-openkp - https://openstax.org/books/college-algebra-corequisite-support-2e/pages/7-7-solving-systems-with-inverses - Finding the Multiplicative Inverse of 3×3 Matrices\n",
      "['inverse']\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-openkp - https://openstax.org/books/college-algebra-corequisite-support-2e/pages/5-5-zeros-of-polynomial-functions - Solving Real-World Applications \n",
      "[]\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-openkp - https://openstax.org/books/chemistry-2e/pages/12-5-collision-theory - Learning Objectives\n",
      "['collision theory']\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-openkp - https://openstax.org/books/college-algebra-corequisite-support-2e/pages/6-4-graphs-of-logarithmic-functions - Graphing a Horizontal Shift of \n",
      "['graphing' 'horizontal shift']\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-openkp - https://openstax.org/books/biology-ap-courses/pages/35-4-aquatic-biomes - Estuaries: Where the Ocean Meets Fresh Water\n",
      "['estuaries']\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-openkp - https://openstax.org/books/introduction-business/pages/13-1-transforming-businesses-through-information - Data and Information Systems\n",
      "['information systems']\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-openkp - https://openstax.org/books/biology-ap-courses/pages/24-1-animal-form-and-function - Body Plans\n",
      "['animals' 'body plans' 'body symmetry' 'symmetry']\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-openkp - https://openstax.org/books/university-physics-volume-2/pages/14-2-self-inductance-and-inductors - Rectangular Toroid\n",
      "['rectangular toroid']\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-openkp - https://openstax.org/books/astronomy-2e/pages/22-1-evolution-from-the-main-sequence-to-red-giants - Learning Objectives\n",
      "[]\n",
      "\n",
      "ml6team/keyphrase-extraction-distilbert-openkp - https://openstax.org/books/introduction-philosophy/pages/10-1-the-challenge-of-bioethics - Human Trials in Historically Marginalized Communities\n",
      "['human trials']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d640286e364049bdb78557970d204af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df2a1b67a8247219dc29e0d61b45548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61bd0532b2b47e58d945b87b5be261c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783b22fa984348419198e3caf38f6042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48be366bf8dd41248884e34fcb0bf1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0a9d17254a47928724c4ba6bb40e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc9bd841193477cbbf8c7df19a09d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml6team/keyphrase-extraction-kbir-kptimes - https://openstax.org/books/college-algebra-corequisite-support-2e/pages/7-7-solving-systems-with-inverses - Finding the Multiplicative Inverse of 3×3 Matrices\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1778) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 1778].  Tensor sizes: [1, 514]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m samples:\n\u001b[1;32m      9\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m{\u001b[39;00msample\u001b[39m.\u001b[39m_\u001b[39m.\u001b[39msection_url\u001b[39m}\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m{\u001b[39;00msample\u001b[39m.\u001b[39m_\u001b[39m.\u001b[39msubsection\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mprint\u001b[39m(pipe(sample\u001b[39m.\u001b[39;49mtext))\n\u001b[1;32m     11\u001b[0m     \u001b[39mprint\u001b[39m()\n",
      "File \u001b[0;32m~/conda_envs/keyword-extraction/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:216\u001b[0m, in \u001b[0;36mTokenClassificationPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m offset_mapping:\n\u001b[1;32m    214\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39moffset_mapping\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m offset_mapping\n\u001b[0;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/conda_envs/keyword-extraction/lib/python3.11/site-packages/transformers/pipelines/base.py:1084\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1076\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[1;32m   1077\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[1;32m   1078\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1081\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m     )\n\u001b[1;32m   1083\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1084\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/conda_envs/keyword-extraction/lib/python3.11/site-packages/transformers/pipelines/base.py:1091\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1090\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1091\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1092\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1093\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/conda_envs/keyword-extraction/lib/python3.11/site-packages/transformers/pipelines/base.py:992\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m    991\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 992\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m    993\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    994\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/conda_envs/keyword-extraction/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:242\u001b[0m, in \u001b[0;36mTokenClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    240\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(model_inputs\u001b[39m.\u001b[39mdata)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    241\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    244\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    245\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlogits\u001b[39m\u001b[39m\"\u001b[39m: logits,\n\u001b[1;32m    246\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mspecial_tokens_mask\u001b[39m\u001b[39m\"\u001b[39m: special_tokens_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_inputs,\n\u001b[1;32m    250\u001b[0m }\n",
      "File \u001b[0;32m~/conda_envs/keyword-extraction/lib/python3.11/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda_envs/keyword-extraction/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:1404\u001b[0m, in \u001b[0;36mRobertaForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1398\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1399\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1400\u001b[0m \u001b[39m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[1;32m   1401\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1402\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1404\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroberta(\n\u001b[1;32m   1405\u001b[0m     input_ids,\n\u001b[1;32m   1406\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1407\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1408\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1409\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1410\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1411\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1412\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1413\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1414\u001b[0m )\n\u001b[1;32m   1416\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1418\u001b[0m sequence_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(sequence_output)\n",
      "File \u001b[0;32m~/conda_envs/keyword-extraction/lib/python3.11/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda_envs/keyword-extraction/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:817\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings, \u001b[39m\"\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    816\u001b[0m     buffered_token_type_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings\u001b[39m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[0;32m--> 817\u001b[0m     buffered_token_type_ids_expanded \u001b[39m=\u001b[39m buffered_token_type_ids\u001b[39m.\u001b[39;49mexpand(batch_size, seq_length)\n\u001b[1;32m    818\u001b[0m     token_type_ids \u001b[39m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[1;32m    819\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1778) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 1778].  Tensor sizes: [1, 514]"
     ]
    }
   ],
   "source": [
    "for type, models in model_dict.items():\n",
    "    for model_name in models:\n",
    "        if type == 'extraction':\n",
    "            pipe = KeyphraseExtractionPipeline(model=model_name)\n",
    "        elif type == 'generation':\n",
    "            pipe = KeyphraseGenerationPipeline(model=model_name,\n",
    "                                               truncation=True)\n",
    "        for sample in samples:\n",
    "            print(f'{model_name} - {sample._.section_url} - {sample._.subsection}')\n",
    "            print(pipe(sample.text))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keyword-extraction]",
   "language": "python",
   "name": "conda-env-keyword-extraction-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
